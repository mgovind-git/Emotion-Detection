{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e592ce3-6933-471c-85d6-b661ec6f69ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\govin\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\govin\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m391s\u001b[0m 866ms/step - accuracy: 0.2446 - loss: 1.8414 - val_accuracy: 0.2651 - val_loss: 1.7827\n",
      "Epoch 2/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 83ms/step - accuracy: 0.2646 - loss: 1.7737 - val_accuracy: 0.3272 - val_loss: 1.7129\n",
      "Epoch 3/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 86ms/step - accuracy: 0.3045 - loss: 1.7288 - val_accuracy: 0.3644 - val_loss: 1.6408\n",
      "Epoch 4/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 86ms/step - accuracy: 0.3272 - loss: 1.6887 - val_accuracy: 0.3624 - val_loss: 1.5945\n",
      "Epoch 5/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 86ms/step - accuracy: 0.3396 - loss: 1.6669 - val_accuracy: 0.3936 - val_loss: 1.5721\n",
      "Epoch 6/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 86ms/step - accuracy: 0.3616 - loss: 1.6297 - val_accuracy: 0.4230 - val_loss: 1.5114\n",
      "Epoch 7/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 84ms/step - accuracy: 0.3783 - loss: 1.6026 - val_accuracy: 0.4305 - val_loss: 1.4876\n",
      "Epoch 8/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 85ms/step - accuracy: 0.3855 - loss: 1.5863 - val_accuracy: 0.4404 - val_loss: 1.4746\n",
      "Epoch 9/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 80ms/step - accuracy: 0.3893 - loss: 1.5629 - val_accuracy: 0.4525 - val_loss: 1.4471\n",
      "Epoch 10/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 78ms/step - accuracy: 0.4066 - loss: 1.5470 - val_accuracy: 0.4511 - val_loss: 1.4491\n",
      "Epoch 11/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 77ms/step - accuracy: 0.4124 - loss: 1.5255 - val_accuracy: 0.4581 - val_loss: 1.4213\n",
      "Epoch 12/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 77ms/step - accuracy: 0.4175 - loss: 1.5155 - val_accuracy: 0.4769 - val_loss: 1.3842\n",
      "Epoch 13/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 77ms/step - accuracy: 0.4212 - loss: 1.5074 - val_accuracy: 0.4805 - val_loss: 1.3769\n",
      "Epoch 14/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 77ms/step - accuracy: 0.4294 - loss: 1.4914 - val_accuracy: 0.4854 - val_loss: 1.3639\n",
      "Epoch 15/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 78ms/step - accuracy: 0.4377 - loss: 1.4689 - val_accuracy: 0.4912 - val_loss: 1.3458\n",
      "Epoch 16/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 77ms/step - accuracy: 0.4473 - loss: 1.4554 - val_accuracy: 0.4863 - val_loss: 1.3598\n",
      "Epoch 17/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 79ms/step - accuracy: 0.4439 - loss: 1.4482 - val_accuracy: 0.5052 - val_loss: 1.3249\n",
      "Epoch 18/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 78ms/step - accuracy: 0.4557 - loss: 1.4303 - val_accuracy: 0.5018 - val_loss: 1.3213\n",
      "Epoch 19/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 79ms/step - accuracy: 0.4563 - loss: 1.4271 - val_accuracy: 0.5059 - val_loss: 1.3210\n",
      "Epoch 20/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 77ms/step - accuracy: 0.4607 - loss: 1.4152 - val_accuracy: 0.5057 - val_loss: 1.3143\n",
      "Epoch 21/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 78ms/step - accuracy: 0.4625 - loss: 1.4093 - val_accuracy: 0.5092 - val_loss: 1.2973\n",
      "Epoch 22/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 77ms/step - accuracy: 0.4632 - loss: 1.4088 - val_accuracy: 0.5109 - val_loss: 1.3002\n",
      "Epoch 23/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 78ms/step - accuracy: 0.4741 - loss: 1.3816 - val_accuracy: 0.5145 - val_loss: 1.2954\n",
      "Epoch 24/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 77ms/step - accuracy: 0.4794 - loss: 1.3720 - val_accuracy: 0.5198 - val_loss: 1.2725\n",
      "Epoch 25/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 77ms/step - accuracy: 0.4785 - loss: 1.3748 - val_accuracy: 0.5174 - val_loss: 1.2757\n",
      "Epoch 26/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 78ms/step - accuracy: 0.4827 - loss: 1.3626 - val_accuracy: 0.5312 - val_loss: 1.2482\n",
      "Epoch 27/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 78ms/step - accuracy: 0.4875 - loss: 1.3605 - val_accuracy: 0.5212 - val_loss: 1.2607\n",
      "Epoch 28/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 77ms/step - accuracy: 0.4840 - loss: 1.3598 - val_accuracy: 0.5217 - val_loss: 1.2711\n",
      "Epoch 29/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 77ms/step - accuracy: 0.4888 - loss: 1.3427 - val_accuracy: 0.5290 - val_loss: 1.2610\n",
      "Epoch 30/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 77ms/step - accuracy: 0.4896 - loss: 1.3293 - val_accuracy: 0.5340 - val_loss: 1.2349\n",
      "Epoch 31/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 77ms/step - accuracy: 0.4938 - loss: 1.3342 - val_accuracy: 0.5332 - val_loss: 1.2370\n",
      "Epoch 32/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 77ms/step - accuracy: 0.4933 - loss: 1.3246 - val_accuracy: 0.5351 - val_loss: 1.2315\n",
      "Epoch 33/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 78ms/step - accuracy: 0.5000 - loss: 1.3182 - val_accuracy: 0.5421 - val_loss: 1.2172\n",
      "Epoch 34/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 78ms/step - accuracy: 0.5002 - loss: 1.3184 - val_accuracy: 0.5439 - val_loss: 1.2234\n",
      "Epoch 35/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 77ms/step - accuracy: 0.5033 - loss: 1.3099 - val_accuracy: 0.5454 - val_loss: 1.2143\n",
      "Epoch 36/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 79ms/step - accuracy: 0.5038 - loss: 1.3016 - val_accuracy: 0.5373 - val_loss: 1.2240\n",
      "Epoch 37/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 83ms/step - accuracy: 0.4992 - loss: 1.3074 - val_accuracy: 0.5496 - val_loss: 1.1900\n",
      "Epoch 38/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 83ms/step - accuracy: 0.5021 - loss: 1.3034 - val_accuracy: 0.5417 - val_loss: 1.2186\n",
      "Epoch 39/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 83ms/step - accuracy: 0.5138 - loss: 1.2812 - val_accuracy: 0.5522 - val_loss: 1.1780\n",
      "Epoch 40/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 80ms/step - accuracy: 0.5140 - loss: 1.2824 - val_accuracy: 0.5421 - val_loss: 1.2141\n",
      "Epoch 41/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 81ms/step - accuracy: 0.5164 - loss: 1.2801 - val_accuracy: 0.5620 - val_loss: 1.1748\n",
      "Epoch 42/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 81ms/step - accuracy: 0.5104 - loss: 1.2833 - val_accuracy: 0.5474 - val_loss: 1.1923\n",
      "Epoch 43/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5211 - loss: 1.2713 - val_accuracy: 0.5560 - val_loss: 1.1660\n",
      "Epoch 44/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 81ms/step - accuracy: 0.5192 - loss: 1.2707 - val_accuracy: 0.5552 - val_loss: 1.1814\n",
      "Epoch 45/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 80ms/step - accuracy: 0.5211 - loss: 1.2585 - val_accuracy: 0.5626 - val_loss: 1.1524\n",
      "Epoch 46/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 81ms/step - accuracy: 0.5174 - loss: 1.2690 - val_accuracy: 0.5616 - val_loss: 1.1614\n",
      "Epoch 47/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 81ms/step - accuracy: 0.5271 - loss: 1.2552 - val_accuracy: 0.5637 - val_loss: 1.1571\n",
      "Epoch 48/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 81ms/step - accuracy: 0.5241 - loss: 1.2557 - val_accuracy: 0.5570 - val_loss: 1.1755\n",
      "Epoch 49/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5263 - loss: 1.2503 - val_accuracy: 0.5648 - val_loss: 1.1546\n",
      "Epoch 50/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 81ms/step - accuracy: 0.5270 - loss: 1.2445 - val_accuracy: 0.5602 - val_loss: 1.1558\n",
      "Epoch 51/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 81ms/step - accuracy: 0.5239 - loss: 1.2558 - val_accuracy: 0.5688 - val_loss: 1.1549\n",
      "Epoch 52/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 81ms/step - accuracy: 0.5301 - loss: 1.2386 - val_accuracy: 0.5621 - val_loss: 1.1575\n",
      "Epoch 53/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 81ms/step - accuracy: 0.5359 - loss: 1.2332 - val_accuracy: 0.5738 - val_loss: 1.1296\n",
      "Epoch 54/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 80ms/step - accuracy: 0.5311 - loss: 1.2302 - val_accuracy: 0.5658 - val_loss: 1.1535\n",
      "Epoch 55/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5322 - loss: 1.2357 - val_accuracy: 0.5705 - val_loss: 1.1454\n",
      "Epoch 56/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 81ms/step - accuracy: 0.5381 - loss: 1.2201 - val_accuracy: 0.5755 - val_loss: 1.1267\n",
      "Epoch 57/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 81ms/step - accuracy: 0.5396 - loss: 1.2226 - val_accuracy: 0.5729 - val_loss: 1.1293\n",
      "Epoch 58/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 81ms/step - accuracy: 0.5390 - loss: 1.2150 - val_accuracy: 0.5768 - val_loss: 1.1249\n",
      "Epoch 59/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 83ms/step - accuracy: 0.5377 - loss: 1.2209 - val_accuracy: 0.5787 - val_loss: 1.1171\n",
      "Epoch 60/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 89ms/step - accuracy: 0.5393 - loss: 1.2043 - val_accuracy: 0.5828 - val_loss: 1.1158\n",
      "Epoch 61/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 88ms/step - accuracy: 0.5459 - loss: 1.2112 - val_accuracy: 0.5750 - val_loss: 1.1237\n",
      "Epoch 62/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 84ms/step - accuracy: 0.5435 - loss: 1.2058 - val_accuracy: 0.5821 - val_loss: 1.1136\n",
      "Epoch 63/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 83ms/step - accuracy: 0.5400 - loss: 1.2103 - val_accuracy: 0.5736 - val_loss: 1.1329\n",
      "Epoch 64/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5441 - loss: 1.2044 - val_accuracy: 0.5822 - val_loss: 1.1208\n",
      "Epoch 65/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5432 - loss: 1.2103 - val_accuracy: 0.5802 - val_loss: 1.1078\n",
      "Epoch 66/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5505 - loss: 1.1888 - val_accuracy: 0.5825 - val_loss: 1.1092\n",
      "Epoch 67/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 83ms/step - accuracy: 0.5494 - loss: 1.1972 - val_accuracy: 0.5839 - val_loss: 1.0978\n",
      "Epoch 68/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 89ms/step - accuracy: 0.5507 - loss: 1.1935 - val_accuracy: 0.5889 - val_loss: 1.0934\n",
      "Epoch 69/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5492 - loss: 1.1952 - val_accuracy: 0.5832 - val_loss: 1.1156\n",
      "Epoch 70/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 81ms/step - accuracy: 0.5538 - loss: 1.1819 - val_accuracy: 0.5843 - val_loss: 1.1070\n",
      "Epoch 71/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 81ms/step - accuracy: 0.5523 - loss: 1.1907 - val_accuracy: 0.5917 - val_loss: 1.0890\n",
      "Epoch 72/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 81ms/step - accuracy: 0.5516 - loss: 1.1920 - val_accuracy: 0.5907 - val_loss: 1.0900\n",
      "Epoch 73/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5532 - loss: 1.1841 - val_accuracy: 0.5894 - val_loss: 1.0891\n",
      "Epoch 74/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5536 - loss: 1.1774 - val_accuracy: 0.5857 - val_loss: 1.0945\n",
      "Epoch 75/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5523 - loss: 1.1796 - val_accuracy: 0.5904 - val_loss: 1.0857\n",
      "Epoch 76/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5560 - loss: 1.1768 - val_accuracy: 0.5903 - val_loss: 1.1008\n",
      "Epoch 77/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5582 - loss: 1.1843 - val_accuracy: 0.5931 - val_loss: 1.0937\n",
      "Epoch 78/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5614 - loss: 1.1629 - val_accuracy: 0.5928 - val_loss: 1.0851\n",
      "Epoch 79/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 83ms/step - accuracy: 0.5542 - loss: 1.1779 - val_accuracy: 0.5956 - val_loss: 1.0845\n",
      "Epoch 80/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 94ms/step - accuracy: 0.5531 - loss: 1.1702 - val_accuracy: 0.6013 - val_loss: 1.0721\n",
      "Epoch 81/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 81ms/step - accuracy: 0.5559 - loss: 1.1672 - val_accuracy: 0.5960 - val_loss: 1.0777\n",
      "Epoch 82/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5584 - loss: 1.1682 - val_accuracy: 0.5996 - val_loss: 1.0709\n",
      "Epoch 83/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 81ms/step - accuracy: 0.5646 - loss: 1.1583 - val_accuracy: 0.5971 - val_loss: 1.0736\n",
      "Epoch 84/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 81ms/step - accuracy: 0.5650 - loss: 1.1545 - val_accuracy: 0.5946 - val_loss: 1.0859\n",
      "Epoch 85/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 81ms/step - accuracy: 0.5573 - loss: 1.1661 - val_accuracy: 0.5954 - val_loss: 1.0798\n",
      "Epoch 86/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 81ms/step - accuracy: 0.5636 - loss: 1.1564 - val_accuracy: 0.6003 - val_loss: 1.0738\n",
      "Epoch 87/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 81ms/step - accuracy: 0.5608 - loss: 1.1570 - val_accuracy: 0.5975 - val_loss: 1.0729\n",
      "Epoch 88/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 81ms/step - accuracy: 0.5656 - loss: 1.1543 - val_accuracy: 0.6007 - val_loss: 1.0668\n",
      "Epoch 89/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 80ms/step - accuracy: 0.5644 - loss: 1.1580 - val_accuracy: 0.6002 - val_loss: 1.0692\n",
      "Epoch 90/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5609 - loss: 1.1598 - val_accuracy: 0.5984 - val_loss: 1.0744\n",
      "Epoch 91/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5705 - loss: 1.1413 - val_accuracy: 0.6074 - val_loss: 1.0538\n",
      "Epoch 92/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5693 - loss: 1.1518 - val_accuracy: 0.6009 - val_loss: 1.0631\n",
      "Epoch 93/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5699 - loss: 1.1425 - val_accuracy: 0.6027 - val_loss: 1.0605\n",
      "Epoch 94/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5674 - loss: 1.1424 - val_accuracy: 0.6000 - val_loss: 1.0650\n",
      "Epoch 95/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 81ms/step - accuracy: 0.5734 - loss: 1.1350 - val_accuracy: 0.6031 - val_loss: 1.0624\n",
      "Epoch 96/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 81ms/step - accuracy: 0.5677 - loss: 1.1446 - val_accuracy: 0.6010 - val_loss: 1.0661\n",
      "Epoch 97/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5772 - loss: 1.1323 - val_accuracy: 0.6069 - val_loss: 1.0589\n",
      "Epoch 98/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 81ms/step - accuracy: 0.5727 - loss: 1.1361 - val_accuracy: 0.6002 - val_loss: 1.0646\n",
      "Epoch 99/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5655 - loss: 1.1416 - val_accuracy: 0.6063 - val_loss: 1.0616\n",
      "Epoch 100/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5660 - loss: 1.1462 - val_accuracy: 0.6077 - val_loss: 1.0648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define paths\n",
    "train_dir = \"data/train\"\n",
    "test_dir = \"data/test\"\n",
    "\n",
    "# Image parameters\n",
    "img_width, img_height = 48, 48\n",
    "batch_size = 64\n",
    "num_classes = len(os.listdir(train_dir))  # count emotion folders\n",
    "\n",
    "# Data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Build CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 1)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    validation_data=test_generator\n",
    ")\n",
    "\n",
    "# Save model\n",
    "model.save(\"emotion_model.h5\")\n",
    "print(\"Model trained and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b2ad430-9d15-449d-9d24-522c0b568f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\govin\\MachineLearning\\Project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c8f43bc-545b-4550-9e3b-bf09c7540106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 83ms/step - accuracy: 0.5702 - loss: 1.1329 - val_accuracy: 0.6052 - val_loss: 1.0579\n",
      "Epoch 2/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5755 - loss: 1.1274 - val_accuracy: 0.6067 - val_loss: 1.0511\n",
      "Epoch 3/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5711 - loss: 1.1262 - val_accuracy: 0.6028 - val_loss: 1.0591\n",
      "Epoch 4/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5743 - loss: 1.1217 - val_accuracy: 0.5992 - val_loss: 1.0692\n",
      "Epoch 5/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5782 - loss: 1.1306 - val_accuracy: 0.6043 - val_loss: 1.0522\n",
      "Epoch 6/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5743 - loss: 1.1248 - val_accuracy: 0.6092 - val_loss: 1.0440\n",
      "Epoch 7/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5734 - loss: 1.1277 - val_accuracy: 0.6077 - val_loss: 1.0513\n",
      "Epoch 8/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5749 - loss: 1.1250 - val_accuracy: 0.6115 - val_loss: 1.0466\n",
      "Epoch 9/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5780 - loss: 1.1272 - val_accuracy: 0.5991 - val_loss: 1.0641\n",
      "Epoch 10/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5799 - loss: 1.1149 - val_accuracy: 0.6095 - val_loss: 1.0422\n",
      "Epoch 11/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5782 - loss: 1.1241 - val_accuracy: 0.6101 - val_loss: 1.0418\n",
      "Epoch 12/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5760 - loss: 1.1273 - val_accuracy: 0.6105 - val_loss: 1.0421\n",
      "Epoch 13/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5806 - loss: 1.1156 - val_accuracy: 0.6166 - val_loss: 1.0349\n",
      "Epoch 14/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 81ms/step - accuracy: 0.5781 - loss: 1.1170 - val_accuracy: 0.6094 - val_loss: 1.0424\n",
      "Epoch 15/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 83ms/step - accuracy: 0.5797 - loss: 1.1143 - val_accuracy: 0.6092 - val_loss: 1.0450\n",
      "Epoch 16/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5774 - loss: 1.1165 - val_accuracy: 0.6102 - val_loss: 1.0528\n",
      "Epoch 17/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 83ms/step - accuracy: 0.5723 - loss: 1.1109 - val_accuracy: 0.6138 - val_loss: 1.0426\n",
      "Epoch 18/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5873 - loss: 1.1061 - val_accuracy: 0.6119 - val_loss: 1.0369\n",
      "Epoch 19/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 81ms/step - accuracy: 0.5888 - loss: 1.1009 - val_accuracy: 0.6155 - val_loss: 1.0330\n",
      "Epoch 20/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 81ms/step - accuracy: 0.5819 - loss: 1.1114 - val_accuracy: 0.6152 - val_loss: 1.0347\n",
      "Epoch 21/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5845 - loss: 1.1088 - val_accuracy: 0.6147 - val_loss: 1.0403\n",
      "Epoch 22/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 81ms/step - accuracy: 0.5923 - loss: 1.0945 - val_accuracy: 0.6059 - val_loss: 1.0498\n",
      "Epoch 23/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5807 - loss: 1.1133 - val_accuracy: 0.6094 - val_loss: 1.0416\n",
      "Epoch 24/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5810 - loss: 1.1022 - val_accuracy: 0.6152 - val_loss: 1.0310\n",
      "Epoch 25/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5875 - loss: 1.0911 - val_accuracy: 0.6159 - val_loss: 1.0335\n",
      "Epoch 26/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5846 - loss: 1.0943 - val_accuracy: 0.6119 - val_loss: 1.0365\n",
      "Epoch 27/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 81ms/step - accuracy: 0.5864 - loss: 1.0877 - val_accuracy: 0.6172 - val_loss: 1.0338\n",
      "Epoch 28/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5857 - loss: 1.1081 - val_accuracy: 0.6220 - val_loss: 1.0249\n",
      "Epoch 29/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5945 - loss: 1.0846 - val_accuracy: 0.6134 - val_loss: 1.0311\n",
      "Epoch 30/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 83ms/step - accuracy: 0.5860 - loss: 1.0955 - val_accuracy: 0.6144 - val_loss: 1.0297\n",
      "Epoch 31/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5876 - loss: 1.1004 - val_accuracy: 0.6169 - val_loss: 1.0323\n",
      "Epoch 32/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 83ms/step - accuracy: 0.5919 - loss: 1.0846 - val_accuracy: 0.6186 - val_loss: 1.0341\n",
      "Epoch 33/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5886 - loss: 1.0950 - val_accuracy: 0.6174 - val_loss: 1.0372\n",
      "Epoch 34/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5911 - loss: 1.0858 - val_accuracy: 0.6245 - val_loss: 1.0215\n",
      "Epoch 35/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5909 - loss: 1.0881 - val_accuracy: 0.6241 - val_loss: 1.0206\n",
      "Epoch 36/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 83ms/step - accuracy: 0.5926 - loss: 1.0815 - val_accuracy: 0.6259 - val_loss: 1.0197\n",
      "Epoch 37/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5897 - loss: 1.0905 - val_accuracy: 0.6173 - val_loss: 1.0373\n",
      "Epoch 38/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5863 - loss: 1.0956 - val_accuracy: 0.6226 - val_loss: 1.0173\n",
      "Epoch 39/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 83ms/step - accuracy: 0.5938 - loss: 1.0831 - val_accuracy: 0.6184 - val_loss: 1.0257\n",
      "Epoch 40/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 81ms/step - accuracy: 0.5933 - loss: 1.0842 - val_accuracy: 0.6216 - val_loss: 1.0169\n",
      "Epoch 41/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 81ms/step - accuracy: 0.5891 - loss: 1.0901 - val_accuracy: 0.6145 - val_loss: 1.0236\n",
      "Epoch 42/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5967 - loss: 1.0687 - val_accuracy: 0.6211 - val_loss: 1.0292\n",
      "Epoch 43/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 81ms/step - accuracy: 0.5938 - loss: 1.0725 - val_accuracy: 0.6225 - val_loss: 1.0201\n",
      "Epoch 44/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 83ms/step - accuracy: 0.5902 - loss: 1.0744 - val_accuracy: 0.6191 - val_loss: 1.0273\n",
      "Epoch 45/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 84ms/step - accuracy: 0.5974 - loss: 1.0790 - val_accuracy: 0.6187 - val_loss: 1.0189\n",
      "Epoch 46/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 83ms/step - accuracy: 0.5861 - loss: 1.0824 - val_accuracy: 0.6213 - val_loss: 1.0109\n",
      "Epoch 47/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 83ms/step - accuracy: 0.5954 - loss: 1.0675 - val_accuracy: 0.6223 - val_loss: 1.0274\n",
      "Epoch 48/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 83ms/step - accuracy: 0.5934 - loss: 1.0739 - val_accuracy: 0.6223 - val_loss: 1.0201\n",
      "Epoch 49/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 83ms/step - accuracy: 0.5910 - loss: 1.0790 - val_accuracy: 0.6232 - val_loss: 1.0170\n",
      "Epoch 50/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5994 - loss: 1.0708 - val_accuracy: 0.6261 - val_loss: 1.0070\n",
      "Epoch 51/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 84ms/step - accuracy: 0.5914 - loss: 1.0753 - val_accuracy: 0.6233 - val_loss: 1.0182\n",
      "Epoch 52/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 86ms/step - accuracy: 0.5963 - loss: 1.0734 - val_accuracy: 0.6250 - val_loss: 1.0126\n",
      "Epoch 53/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 85ms/step - accuracy: 0.5983 - loss: 1.0703 - val_accuracy: 0.6250 - val_loss: 1.0229\n",
      "Epoch 54/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5968 - loss: 1.0722 - val_accuracy: 0.6254 - val_loss: 1.0136\n",
      "Epoch 55/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 85ms/step - accuracy: 0.5948 - loss: 1.0669 - val_accuracy: 0.6226 - val_loss: 1.0172\n",
      "Epoch 56/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 83ms/step - accuracy: 0.5991 - loss: 1.0664 - val_accuracy: 0.6208 - val_loss: 1.0182\n",
      "Epoch 57/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 84ms/step - accuracy: 0.5959 - loss: 1.0698 - val_accuracy: 0.6282 - val_loss: 1.0070\n",
      "Epoch 58/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 89ms/step - accuracy: 0.6064 - loss: 1.0551 - val_accuracy: 0.6230 - val_loss: 1.0152\n",
      "Epoch 59/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.5983 - loss: 1.0588 - val_accuracy: 0.6245 - val_loss: 1.0157\n",
      "Epoch 60/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 89ms/step - accuracy: 0.5982 - loss: 1.0563 - val_accuracy: 0.6266 - val_loss: 1.0042\n",
      "Epoch 61/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 80ms/step - accuracy: 0.6030 - loss: 1.0497 - val_accuracy: 0.6335 - val_loss: 0.9969\n",
      "Epoch 62/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 80ms/step - accuracy: 0.6029 - loss: 1.0554 - val_accuracy: 0.6287 - val_loss: 1.0101\n",
      "Epoch 63/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 80ms/step - accuracy: 0.6057 - loss: 1.0501 - val_accuracy: 0.6293 - val_loss: 1.0116\n",
      "Epoch 64/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 80ms/step - accuracy: 0.5994 - loss: 1.0619 - val_accuracy: 0.6251 - val_loss: 1.0057\n",
      "Epoch 65/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 80ms/step - accuracy: 0.6034 - loss: 1.0520 - val_accuracy: 0.6294 - val_loss: 1.0035\n",
      "Epoch 66/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 80ms/step - accuracy: 0.6053 - loss: 1.0502 - val_accuracy: 0.6328 - val_loss: 1.0005\n",
      "Epoch 67/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 79ms/step - accuracy: 0.6005 - loss: 1.0573 - val_accuracy: 0.6304 - val_loss: 1.0077\n",
      "Epoch 68/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 80ms/step - accuracy: 0.6010 - loss: 1.0549 - val_accuracy: 0.6304 - val_loss: 1.0036\n",
      "Epoch 69/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 82ms/step - accuracy: 0.6038 - loss: 1.0490 - val_accuracy: 0.6279 - val_loss: 1.0102\n",
      "Epoch 70/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 80ms/step - accuracy: 0.6013 - loss: 1.0572 - val_accuracy: 0.6290 - val_loss: 1.0041\n",
      "Epoch 71/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 80ms/step - accuracy: 0.5982 - loss: 1.0626 - val_accuracy: 0.6272 - val_loss: 1.0030\n",
      "Epoch 72/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 110ms/step - accuracy: 0.5986 - loss: 1.0487 - val_accuracy: 0.6262 - val_loss: 1.0083\n",
      "Epoch 73/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 125ms/step - accuracy: 0.6001 - loss: 1.0506 - val_accuracy: 0.6318 - val_loss: 0.9968\n",
      "Epoch 74/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 125ms/step - accuracy: 0.6007 - loss: 1.0567 - val_accuracy: 0.6279 - val_loss: 1.0075\n",
      "Epoch 75/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 132ms/step - accuracy: 0.6045 - loss: 1.0470 - val_accuracy: 0.6262 - val_loss: 1.0063\n",
      "Epoch 76/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 132ms/step - accuracy: 0.6037 - loss: 1.0503 - val_accuracy: 0.6356 - val_loss: 0.9979\n",
      "Epoch 77/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 136ms/step - accuracy: 0.6047 - loss: 1.0478 - val_accuracy: 0.6293 - val_loss: 1.0065\n",
      "Epoch 78/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 126ms/step - accuracy: 0.6037 - loss: 1.0488 - val_accuracy: 0.6344 - val_loss: 0.9972\n",
      "Epoch 79/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 126ms/step - accuracy: 0.6076 - loss: 1.0399 - val_accuracy: 0.6319 - val_loss: 0.9968\n",
      "Epoch 80/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 129ms/step - accuracy: 0.6099 - loss: 1.0402 - val_accuracy: 0.6315 - val_loss: 1.0060\n",
      "Epoch 81/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 142ms/step - accuracy: 0.6075 - loss: 1.0413 - val_accuracy: 0.6339 - val_loss: 0.9947\n",
      "Epoch 82/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 130ms/step - accuracy: 0.6042 - loss: 1.0509 - val_accuracy: 0.6328 - val_loss: 0.9903\n",
      "Epoch 83/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 127ms/step - accuracy: 0.6031 - loss: 1.0415 - val_accuracy: 0.6383 - val_loss: 0.9887\n",
      "Epoch 84/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 124ms/step - accuracy: 0.6074 - loss: 1.0375 - val_accuracy: 0.6282 - val_loss: 1.0080\n",
      "Epoch 85/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 124ms/step - accuracy: 0.6037 - loss: 1.0434 - val_accuracy: 0.6340 - val_loss: 0.9967\n",
      "Epoch 86/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 128ms/step - accuracy: 0.6130 - loss: 1.0387 - val_accuracy: 0.6350 - val_loss: 0.9957\n",
      "Epoch 87/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 125ms/step - accuracy: 0.6117 - loss: 1.0291 - val_accuracy: 0.6275 - val_loss: 1.0003\n",
      "Epoch 88/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 129ms/step - accuracy: 0.6101 - loss: 1.0382 - val_accuracy: 0.6307 - val_loss: 0.9995\n",
      "Epoch 89/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 130ms/step - accuracy: 0.6050 - loss: 1.0421 - val_accuracy: 0.6314 - val_loss: 0.9918\n",
      "Epoch 90/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 129ms/step - accuracy: 0.6126 - loss: 1.0286 - val_accuracy: 0.6314 - val_loss: 0.9925\n",
      "Epoch 91/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 131ms/step - accuracy: 0.6098 - loss: 1.0344 - val_accuracy: 0.6290 - val_loss: 0.9973\n",
      "Epoch 92/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 133ms/step - accuracy: 0.6142 - loss: 1.0259 - val_accuracy: 0.6354 - val_loss: 0.9957\n",
      "Epoch 93/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 131ms/step - accuracy: 0.6146 - loss: 1.0295 - val_accuracy: 0.6360 - val_loss: 0.9905\n",
      "Epoch 94/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 133ms/step - accuracy: 0.6123 - loss: 1.0302 - val_accuracy: 0.6362 - val_loss: 0.9901\n",
      "Epoch 95/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 130ms/step - accuracy: 0.6096 - loss: 1.0498 - val_accuracy: 0.6284 - val_loss: 0.9952\n",
      "Epoch 96/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 130ms/step - accuracy: 0.6172 - loss: 1.0132 - val_accuracy: 0.6239 - val_loss: 1.0115\n",
      "Epoch 97/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 130ms/step - accuracy: 0.6195 - loss: 1.0241 - val_accuracy: 0.6296 - val_loss: 1.0020\n",
      "Epoch 98/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 129ms/step - accuracy: 0.6121 - loss: 1.0277 - val_accuracy: 0.6307 - val_loss: 1.0061\n",
      "Epoch 99/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 129ms/step - accuracy: 0.6143 - loss: 1.0309 - val_accuracy: 0.6301 - val_loss: 0.9937\n",
      "Epoch 100/100\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 130ms/step - accuracy: 0.6157 - loss: 1.0262 - val_accuracy: 0.6294 - val_loss: 0.9959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x192dfd589e0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    validation_data=test_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0bb5a5d-45af-4599-a122-80f4ec65d0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad4bdf78-7fe5-4a36-8232-7d5a60bdb4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12d952c2-83f6-47b7-a137-726c5aac0b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    }
   ],
   "source": [
    "model.save(\"my_model2.keras\", save_format=\"keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786545a2-f1aa-4e27-9058-6a36e9888e48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
