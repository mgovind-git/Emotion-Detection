{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9d5cd6f-c075-46e1-82d8-a5f162f8a6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">262,272</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">903</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │          \u001b[38;5;34m73,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m262,272\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │             \u001b[38;5;34m903\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">356,743</span> (1.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m356,743\u001b[0m (1.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">356,295</span> (1.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m356,295\u001b[0m (1.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Conv2D, MaxPooling2D, Dropout,\n",
    "                                     Flatten, Dense, BatchNormalization)\n",
    "\n",
    "# Define model architecture\n",
    "def build_emotion_model(input_shape=(48, 48, 1), num_classes=7):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Build and compile\n",
    "model = build_emotion_model()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb06961c-7793-4b75-bace-a8548921aa5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n",
      "Epoch 1/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 696ms/step - accuracy: 0.2369 - loss: 2.0003 - val_accuracy: 0.2453 - val_loss: 1.9840\n",
      "Epoch 2/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 55ms/step - accuracy: 0.3300 - loss: 1.6627 - val_accuracy: 0.4211 - val_loss: 1.5024\n",
      "Epoch 3/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 55ms/step - accuracy: 0.3774 - loss: 1.5669 - val_accuracy: 0.4586 - val_loss: 1.4252\n",
      "Epoch 4/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.4125 - loss: 1.4956 - val_accuracy: 0.4734 - val_loss: 1.4090\n",
      "Epoch 5/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 58ms/step - accuracy: 0.4348 - loss: 1.4442 - val_accuracy: 0.4794 - val_loss: 1.3806\n",
      "Epoch 6/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 62ms/step - accuracy: 0.4528 - loss: 1.4097 - val_accuracy: 0.4918 - val_loss: 1.3118\n",
      "Epoch 7/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 58ms/step - accuracy: 0.4676 - loss: 1.3712 - val_accuracy: 0.4563 - val_loss: 1.3951\n",
      "Epoch 8/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 55ms/step - accuracy: 0.4752 - loss: 1.3526 - val_accuracy: 0.5213 - val_loss: 1.2531\n",
      "Epoch 9/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.4939 - loss: 1.3151 - val_accuracy: 0.5234 - val_loss: 1.2541\n",
      "Epoch 10/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 55ms/step - accuracy: 0.5034 - loss: 1.2938 - val_accuracy: 0.5118 - val_loss: 1.2803\n",
      "Epoch 11/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 55ms/step - accuracy: 0.5027 - loss: 1.2875 - val_accuracy: 0.5138 - val_loss: 1.2570\n",
      "Epoch 12/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 57ms/step - accuracy: 0.5213 - loss: 1.2549 - val_accuracy: 0.4987 - val_loss: 1.3239\n",
      "Epoch 13/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 58ms/step - accuracy: 0.5336 - loss: 1.2264 - val_accuracy: 0.5304 - val_loss: 1.2604\n",
      "Epoch 14/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.5418 - loss: 1.2114 - val_accuracy: 0.5343 - val_loss: 1.2552\n",
      "Epoch 15/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 57ms/step - accuracy: 0.5446 - loss: 1.2010 - val_accuracy: 0.5425 - val_loss: 1.2064\n",
      "Epoch 16/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.5464 - loss: 1.1930 - val_accuracy: 0.4997 - val_loss: 1.3302\n",
      "Epoch 17/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.5591 - loss: 1.1656 - val_accuracy: 0.5724 - val_loss: 1.1418\n",
      "Epoch 18/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.5667 - loss: 1.1460 - val_accuracy: 0.5698 - val_loss: 1.1645\n",
      "Epoch 19/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.5691 - loss: 1.1390 - val_accuracy: 0.5695 - val_loss: 1.1455\n",
      "Epoch 20/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 55ms/step - accuracy: 0.5761 - loss: 1.1118 - val_accuracy: 0.5825 - val_loss: 1.1126\n",
      "Epoch 21/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 57ms/step - accuracy: 0.5807 - loss: 1.0991 - val_accuracy: 0.5846 - val_loss: 1.1133\n",
      "Epoch 22/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.5870 - loss: 1.0901 - val_accuracy: 0.5678 - val_loss: 1.1866\n",
      "Epoch 23/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.5964 - loss: 1.0702 - val_accuracy: 0.5670 - val_loss: 1.1643\n",
      "Epoch 24/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.5934 - loss: 1.0719 - val_accuracy: 0.5444 - val_loss: 1.2063\n",
      "Epoch 25/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.5953 - loss: 1.0650 - val_accuracy: 0.5789 - val_loss: 1.1110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_dir = 'data/train'\n",
    "val_dir = 'data/test'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(48, 48),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=64,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(48, 48),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=64,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Training\n",
    "model.fit(train_generator, validation_data=val_generator, epochs=25)\n",
    "\n",
    "# Save the model\n",
    "model.save('Emotion_Detection.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "217cd24c-6e18-42c4-ac86-dbf8fb3a8381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.6010 - loss: 1.0575 - val_accuracy: 0.5802 - val_loss: 1.1102\n",
      "Epoch 2/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.6028 - loss: 1.0427 - val_accuracy: 0.5890 - val_loss: 1.1188\n",
      "Epoch 3/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.6064 - loss: 1.0413 - val_accuracy: 0.5808 - val_loss: 1.1612\n",
      "Epoch 4/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.6109 - loss: 1.0260 - val_accuracy: 0.5805 - val_loss: 1.1366\n",
      "Epoch 5/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.6142 - loss: 1.0101 - val_accuracy: 0.5712 - val_loss: 1.1586\n",
      "Epoch 6/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.6218 - loss: 1.0026 - val_accuracy: 0.5517 - val_loss: 1.2156\n",
      "Epoch 7/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.6286 - loss: 0.9849 - val_accuracy: 0.5982 - val_loss: 1.1082\n",
      "Epoch 8/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.6290 - loss: 0.9772 - val_accuracy: 0.5947 - val_loss: 1.1067\n",
      "Epoch 9/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.6339 - loss: 0.9741 - val_accuracy: 0.6014 - val_loss: 1.0847\n",
      "Epoch 10/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.6363 - loss: 0.9653 - val_accuracy: 0.5874 - val_loss: 1.1314\n",
      "Epoch 11/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.6393 - loss: 0.9494 - val_accuracy: 0.5991 - val_loss: 1.0937\n",
      "Epoch 12/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.6418 - loss: 0.9537 - val_accuracy: 0.5744 - val_loss: 1.1477\n",
      "Epoch 13/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.6390 - loss: 0.9441 - val_accuracy: 0.5798 - val_loss: 1.1468\n",
      "Epoch 14/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.6453 - loss: 0.9426 - val_accuracy: 0.5875 - val_loss: 1.1165\n",
      "Epoch 15/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.6572 - loss: 0.9131 - val_accuracy: 0.5957 - val_loss: 1.0882\n",
      "Epoch 16/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.6561 - loss: 0.9079 - val_accuracy: 0.6042 - val_loss: 1.1117\n",
      "Epoch 17/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.6604 - loss: 0.8980 - val_accuracy: 0.5945 - val_loss: 1.1264\n",
      "Epoch 18/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.6596 - loss: 0.9056 - val_accuracy: 0.6021 - val_loss: 1.1093\n",
      "Epoch 19/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.6628 - loss: 0.8854 - val_accuracy: 0.5772 - val_loss: 1.1734\n",
      "Epoch 20/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.6617 - loss: 0.8915 - val_accuracy: 0.5894 - val_loss: 1.1297\n",
      "Epoch 21/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.6628 - loss: 0.8840 - val_accuracy: 0.5977 - val_loss: 1.0917\n",
      "Epoch 22/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 57ms/step - accuracy: 0.6604 - loss: 0.8832 - val_accuracy: 0.5882 - val_loss: 1.1472\n",
      "Epoch 23/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.6639 - loss: 0.8908 - val_accuracy: 0.5960 - val_loss: 1.1233\n",
      "Epoch 24/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.6764 - loss: 0.8635 - val_accuracy: 0.5991 - val_loss: 1.1453\n",
      "Epoch 25/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.6740 - loss: 0.8595 - val_accuracy: 0.6063 - val_loss: 1.0979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22d88d503b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, validation_data=val_generator, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38121ac4-146f-4f6a-b141-55018b90576d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.6683 - loss: 0.8661 - val_accuracy: 0.6119 - val_loss: 1.1029\n",
      "Epoch 2/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 55ms/step - accuracy: 0.6774 - loss: 0.8575 - val_accuracy: 0.5876 - val_loss: 1.1621\n",
      "Epoch 3/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 55ms/step - accuracy: 0.6819 - loss: 0.8488 - val_accuracy: 0.5936 - val_loss: 1.1511\n",
      "Epoch 4/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 55ms/step - accuracy: 0.6800 - loss: 0.8492 - val_accuracy: 0.6084 - val_loss: 1.1153\n",
      "Epoch 5/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.6782 - loss: 0.8517 - val_accuracy: 0.5972 - val_loss: 1.1590\n",
      "Epoch 6/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 55ms/step - accuracy: 0.6803 - loss: 0.8475 - val_accuracy: 0.6096 - val_loss: 1.1290\n",
      "Epoch 7/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 55ms/step - accuracy: 0.6794 - loss: 0.8487 - val_accuracy: 0.5861 - val_loss: 1.1759\n",
      "Epoch 8/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 54ms/step - accuracy: 0.6831 - loss: 0.8426 - val_accuracy: 0.6027 - val_loss: 1.1313\n",
      "Epoch 9/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 55ms/step - accuracy: 0.6874 - loss: 0.8214 - val_accuracy: 0.6166 - val_loss: 1.0787\n",
      "Epoch 10/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 55ms/step - accuracy: 0.6831 - loss: 0.8323 - val_accuracy: 0.6091 - val_loss: 1.1373\n",
      "Epoch 11/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 55ms/step - accuracy: 0.6950 - loss: 0.8093 - val_accuracy: 0.5949 - val_loss: 1.1200\n",
      "Epoch 12/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 55ms/step - accuracy: 0.6961 - loss: 0.8095 - val_accuracy: 0.6092 - val_loss: 1.1295\n",
      "Epoch 13/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 55ms/step - accuracy: 0.7016 - loss: 0.8007 - val_accuracy: 0.6116 - val_loss: 1.1349\n",
      "Epoch 14/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 55ms/step - accuracy: 0.6920 - loss: 0.8192 - val_accuracy: 0.6055 - val_loss: 1.1351\n",
      "Epoch 15/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 55ms/step - accuracy: 0.6909 - loss: 0.8071 - val_accuracy: 0.6181 - val_loss: 1.0950\n",
      "Epoch 16/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 55ms/step - accuracy: 0.6943 - loss: 0.8079 - val_accuracy: 0.6064 - val_loss: 1.1060\n",
      "Epoch 17/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 55ms/step - accuracy: 0.6972 - loss: 0.8025 - val_accuracy: 0.5814 - val_loss: 1.1709\n",
      "Epoch 18/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 55ms/step - accuracy: 0.7008 - loss: 0.8047 - val_accuracy: 0.5777 - val_loss: 1.2028\n",
      "Epoch 19/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 55ms/step - accuracy: 0.7016 - loss: 0.7914 - val_accuracy: 0.6045 - val_loss: 1.1938\n",
      "Epoch 20/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 55ms/step - accuracy: 0.7002 - loss: 0.7970 - val_accuracy: 0.6115 - val_loss: 1.1129\n",
      "Epoch 21/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 55ms/step - accuracy: 0.7054 - loss: 0.7849 - val_accuracy: 0.6176 - val_loss: 1.1477\n",
      "Epoch 22/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.7048 - loss: 0.7764 - val_accuracy: 0.6030 - val_loss: 1.1237\n",
      "Epoch 23/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 55ms/step - accuracy: 0.7025 - loss: 0.7855 - val_accuracy: 0.6174 - val_loss: 1.1121\n",
      "Epoch 24/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 55ms/step - accuracy: 0.7067 - loss: 0.7826 - val_accuracy: 0.6060 - val_loss: 1.1412\n",
      "Epoch 25/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.7080 - loss: 0.7857 - val_accuracy: 0.6138 - val_loss: 1.1646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22d9ea7e780>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, validation_data=val_generator, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a54502a-22f1-4287-9224-fe54da26af39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.7081 - loss: 0.7754 - val_accuracy: 0.6222 - val_loss: 1.1162\n",
      "Epoch 2/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 55ms/step - accuracy: 0.7038 - loss: 0.7792 - val_accuracy: 0.6133 - val_loss: 1.1234\n",
      "Epoch 3/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.7118 - loss: 0.7600 - val_accuracy: 0.6073 - val_loss: 1.1360\n",
      "Epoch 4/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.7134 - loss: 0.7584 - val_accuracy: 0.6236 - val_loss: 1.0995\n",
      "Epoch 5/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.7154 - loss: 0.7630 - val_accuracy: 0.6212 - val_loss: 1.1197\n",
      "Epoch 6/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 55ms/step - accuracy: 0.7110 - loss: 0.7655 - val_accuracy: 0.6251 - val_loss: 1.1134\n",
      "Epoch 7/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.7175 - loss: 0.7419 - val_accuracy: 0.6000 - val_loss: 1.1516\n",
      "Epoch 8/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.7236 - loss: 0.7426 - val_accuracy: 0.5997 - val_loss: 1.1668\n",
      "Epoch 9/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.7117 - loss: 0.7607 - val_accuracy: 0.6271 - val_loss: 1.1235\n",
      "Epoch 10/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.7231 - loss: 0.7413 - val_accuracy: 0.6188 - val_loss: 1.1295\n",
      "Epoch 11/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.7254 - loss: 0.7301 - val_accuracy: 0.6213 - val_loss: 1.1526\n",
      "Epoch 12/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 57ms/step - accuracy: 0.7235 - loss: 0.7405 - val_accuracy: 0.6252 - val_loss: 1.1121\n",
      "Epoch 13/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.7229 - loss: 0.7465 - val_accuracy: 0.6174 - val_loss: 1.1241\n",
      "Epoch 14/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.7219 - loss: 0.7411 - val_accuracy: 0.6043 - val_loss: 1.1510\n",
      "Epoch 15/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - accuracy: 0.7272 - loss: 0.7413 - val_accuracy: 0.6241 - val_loss: 1.1391\n",
      "Epoch 16/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 59ms/step - accuracy: 0.7329 - loss: 0.7157 - val_accuracy: 0.6173 - val_loss: 1.1336\n",
      "Epoch 17/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 58ms/step - accuracy: 0.7251 - loss: 0.7379 - val_accuracy: 0.6229 - val_loss: 1.1478\n",
      "Epoch 18/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 57ms/step - accuracy: 0.7305 - loss: 0.7229 - val_accuracy: 0.6158 - val_loss: 1.1534\n",
      "Epoch 19/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 58ms/step - accuracy: 0.7231 - loss: 0.7393 - val_accuracy: 0.5754 - val_loss: 1.2197\n",
      "Epoch 20/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 58ms/step - accuracy: 0.7310 - loss: 0.7135 - val_accuracy: 0.6094 - val_loss: 1.1579\n",
      "Epoch 21/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 58ms/step - accuracy: 0.7317 - loss: 0.7212 - val_accuracy: 0.6180 - val_loss: 1.1320\n",
      "Epoch 22/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 59ms/step - accuracy: 0.7289 - loss: 0.7328 - val_accuracy: 0.6248 - val_loss: 1.1596\n",
      "Epoch 23/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 57ms/step - accuracy: 0.7364 - loss: 0.7098 - val_accuracy: 0.6199 - val_loss: 1.1334\n",
      "Epoch 24/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 57ms/step - accuracy: 0.7334 - loss: 0.7065 - val_accuracy: 0.6169 - val_loss: 1.1343\n",
      "Epoch 25/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 57ms/step - accuracy: 0.7347 - loss: 0.7176 - val_accuracy: 0.6151 - val_loss: 1.1337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22d9e9e2540>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, validation_data=val_generator, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07a9d754-d37a-4a4c-9a5f-1a898da3c27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 59ms/step - accuracy: 0.7399 - loss: 0.6920 - val_accuracy: 0.6145 - val_loss: 1.1196\n",
      "Epoch 2/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 57ms/step - accuracy: 0.7345 - loss: 0.7043 - val_accuracy: 0.6201 - val_loss: 1.1126\n",
      "Epoch 3/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 57ms/step - accuracy: 0.7404 - loss: 0.7034 - val_accuracy: 0.6215 - val_loss: 1.1069\n",
      "Epoch 4/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 59ms/step - accuracy: 0.7410 - loss: 0.6996 - val_accuracy: 0.6198 - val_loss: 1.1160\n",
      "Epoch 5/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 58ms/step - accuracy: 0.7384 - loss: 0.7017 - val_accuracy: 0.6016 - val_loss: 1.1510\n",
      "Epoch 6/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 58ms/step - accuracy: 0.7351 - loss: 0.7040 - val_accuracy: 0.6025 - val_loss: 1.1734\n",
      "Epoch 7/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 58ms/step - accuracy: 0.7374 - loss: 0.6978 - val_accuracy: 0.6149 - val_loss: 1.1203\n",
      "Epoch 8/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 59ms/step - accuracy: 0.7438 - loss: 0.6885 - val_accuracy: 0.6174 - val_loss: 1.1280\n",
      "Epoch 9/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 58ms/step - accuracy: 0.7378 - loss: 0.6923 - val_accuracy: 0.6187 - val_loss: 1.1210\n",
      "Epoch 10/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 59ms/step - accuracy: 0.7420 - loss: 0.6926 - val_accuracy: 0.6213 - val_loss: 1.1739\n",
      "Epoch 11/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 59ms/step - accuracy: 0.7341 - loss: 0.7024 - val_accuracy: 0.6251 - val_loss: 1.1094\n",
      "Epoch 12/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 58ms/step - accuracy: 0.7435 - loss: 0.6869 - val_accuracy: 0.6195 - val_loss: 1.1670\n",
      "Epoch 13/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 57ms/step - accuracy: 0.7358 - loss: 0.7019 - val_accuracy: 0.6258 - val_loss: 1.1329\n",
      "Epoch 14/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 58ms/step - accuracy: 0.7461 - loss: 0.6898 - val_accuracy: 0.6241 - val_loss: 1.1395\n",
      "Epoch 15/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 62ms/step - accuracy: 0.7475 - loss: 0.6840 - val_accuracy: 0.6282 - val_loss: 1.1107\n",
      "Epoch 16/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 59ms/step - accuracy: 0.7482 - loss: 0.6822 - val_accuracy: 0.6305 - val_loss: 1.1181\n",
      "Epoch 17/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 60ms/step - accuracy: 0.7424 - loss: 0.6849 - val_accuracy: 0.6290 - val_loss: 1.1610\n",
      "Epoch 18/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 60ms/step - accuracy: 0.7448 - loss: 0.6873 - val_accuracy: 0.6257 - val_loss: 1.1409\n",
      "Epoch 19/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 61ms/step - accuracy: 0.7447 - loss: 0.6845 - val_accuracy: 0.6094 - val_loss: 1.1715\n",
      "Epoch 20/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 59ms/step - accuracy: 0.7457 - loss: 0.6720 - val_accuracy: 0.6234 - val_loss: 1.1706\n",
      "Epoch 21/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 60ms/step - accuracy: 0.7428 - loss: 0.6915 - val_accuracy: 0.6303 - val_loss: 1.1237\n",
      "Epoch 22/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 61ms/step - accuracy: 0.7421 - loss: 0.6819 - val_accuracy: 0.6087 - val_loss: 1.1680\n",
      "Epoch 23/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 60ms/step - accuracy: 0.7521 - loss: 0.6704 - val_accuracy: 0.6244 - val_loss: 1.1337\n",
      "Epoch 24/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 59ms/step - accuracy: 0.7478 - loss: 0.6738 - val_accuracy: 0.6233 - val_loss: 1.1209\n",
      "Epoch 25/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 60ms/step - accuracy: 0.7455 - loss: 0.6843 - val_accuracy: 0.6282 - val_loss: 1.1533\n",
      "Epoch 26/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 63ms/step - accuracy: 0.7525 - loss: 0.6558 - val_accuracy: 0.6259 - val_loss: 1.1329\n",
      "Epoch 27/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 60ms/step - accuracy: 0.7559 - loss: 0.6630 - val_accuracy: 0.6325 - val_loss: 1.1218\n",
      "Epoch 28/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 61ms/step - accuracy: 0.7517 - loss: 0.6693 - val_accuracy: 0.6236 - val_loss: 1.1720\n",
      "Epoch 29/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 60ms/step - accuracy: 0.7522 - loss: 0.6624 - val_accuracy: 0.6319 - val_loss: 1.1178\n",
      "Epoch 30/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 60ms/step - accuracy: 0.7489 - loss: 0.6612 - val_accuracy: 0.6248 - val_loss: 1.1556\n",
      "Epoch 31/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 60ms/step - accuracy: 0.7560 - loss: 0.6584 - val_accuracy: 0.6268 - val_loss: 1.1724\n",
      "Epoch 32/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 61ms/step - accuracy: 0.7517 - loss: 0.6622 - val_accuracy: 0.6160 - val_loss: 1.1527\n",
      "Epoch 33/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 60ms/step - accuracy: 0.7572 - loss: 0.6589 - val_accuracy: 0.6319 - val_loss: 1.1485\n",
      "Epoch 34/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 60ms/step - accuracy: 0.7541 - loss: 0.6622 - val_accuracy: 0.6088 - val_loss: 1.1945\n",
      "Epoch 35/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 60ms/step - accuracy: 0.7530 - loss: 0.6562 - val_accuracy: 0.6297 - val_loss: 1.1500\n",
      "Epoch 36/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 60ms/step - accuracy: 0.7546 - loss: 0.6568 - val_accuracy: 0.6284 - val_loss: 1.1782\n",
      "Epoch 37/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 60ms/step - accuracy: 0.7566 - loss: 0.6549 - val_accuracy: 0.6085 - val_loss: 1.1883\n",
      "Epoch 38/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 60ms/step - accuracy: 0.7574 - loss: 0.6549 - val_accuracy: 0.6251 - val_loss: 1.1486\n",
      "Epoch 39/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 58ms/step - accuracy: 0.7578 - loss: 0.6469 - val_accuracy: 0.6303 - val_loss: 1.1276\n",
      "Epoch 40/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 64ms/step - accuracy: 0.7600 - loss: 0.6435 - val_accuracy: 0.6230 - val_loss: 1.1545\n",
      "Epoch 41/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 70ms/step - accuracy: 0.7572 - loss: 0.6455 - val_accuracy: 0.6335 - val_loss: 1.1483\n",
      "Epoch 42/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 69ms/step - accuracy: 0.7539 - loss: 0.6499 - val_accuracy: 0.6280 - val_loss: 1.1209\n",
      "Epoch 43/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 69ms/step - accuracy: 0.7548 - loss: 0.6517 - val_accuracy: 0.6105 - val_loss: 1.2061\n",
      "Epoch 44/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 69ms/step - accuracy: 0.7583 - loss: 0.6542 - val_accuracy: 0.6344 - val_loss: 1.1539\n",
      "Epoch 45/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 70ms/step - accuracy: 0.7656 - loss: 0.6315 - val_accuracy: 0.6169 - val_loss: 1.1791\n",
      "Epoch 46/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 70ms/step - accuracy: 0.7645 - loss: 0.6388 - val_accuracy: 0.6279 - val_loss: 1.1570\n",
      "Epoch 47/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 71ms/step - accuracy: 0.7571 - loss: 0.6496 - val_accuracy: 0.6219 - val_loss: 1.1887\n",
      "Epoch 48/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 70ms/step - accuracy: 0.7525 - loss: 0.6489 - val_accuracy: 0.6190 - val_loss: 1.1214\n",
      "Epoch 49/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 71ms/step - accuracy: 0.7630 - loss: 0.6350 - val_accuracy: 0.6250 - val_loss: 1.1726\n",
      "Epoch 50/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 71ms/step - accuracy: 0.7594 - loss: 0.6516 - val_accuracy: 0.6322 - val_loss: 1.1569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22d9e9e3950>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, validation_data=val_generator, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9b443e0-a352-444f-b605-01f250bfcfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 74ms/step - accuracy: 0.7560 - loss: 0.6487 - val_accuracy: 0.6282 - val_loss: 1.1793\n",
      "Epoch 2/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 71ms/step - accuracy: 0.7661 - loss: 0.6308 - val_accuracy: 0.6188 - val_loss: 1.1737\n",
      "Epoch 3/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 70ms/step - accuracy: 0.7694 - loss: 0.6244 - val_accuracy: 0.6290 - val_loss: 1.2251\n",
      "Epoch 4/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 70ms/step - accuracy: 0.7624 - loss: 0.6409 - val_accuracy: 0.6232 - val_loss: 1.1552\n",
      "Epoch 5/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 73ms/step - accuracy: 0.7664 - loss: 0.6290 - val_accuracy: 0.6318 - val_loss: 1.1449\n",
      "Epoch 6/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 72ms/step - accuracy: 0.7645 - loss: 0.6334 - val_accuracy: 0.6236 - val_loss: 1.1353\n",
      "Epoch 7/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 70ms/step - accuracy: 0.7621 - loss: 0.6411 - val_accuracy: 0.6319 - val_loss: 1.1610\n",
      "Epoch 8/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 71ms/step - accuracy: 0.7652 - loss: 0.6299 - val_accuracy: 0.6275 - val_loss: 1.1609\n",
      "Epoch 9/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 70ms/step - accuracy: 0.7649 - loss: 0.6266 - val_accuracy: 0.6237 - val_loss: 1.1770\n",
      "Epoch 10/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 70ms/step - accuracy: 0.7661 - loss: 0.6295 - val_accuracy: 0.6298 - val_loss: 1.2029\n",
      "Epoch 11/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 70ms/step - accuracy: 0.7642 - loss: 0.6285 - val_accuracy: 0.6266 - val_loss: 1.1646\n",
      "Epoch 12/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 69ms/step - accuracy: 0.7691 - loss: 0.6201 - val_accuracy: 0.6115 - val_loss: 1.1874\n",
      "Epoch 13/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 71ms/step - accuracy: 0.7659 - loss: 0.6347 - val_accuracy: 0.6213 - val_loss: 1.1577\n",
      "Epoch 14/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 70ms/step - accuracy: 0.7688 - loss: 0.6295 - val_accuracy: 0.6360 - val_loss: 1.1556\n",
      "Epoch 15/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 69ms/step - accuracy: 0.7699 - loss: 0.6287 - val_accuracy: 0.6305 - val_loss: 1.1632\n",
      "Epoch 16/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 70ms/step - accuracy: 0.7578 - loss: 0.6439 - val_accuracy: 0.6311 - val_loss: 1.1921\n",
      "Epoch 17/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 69ms/step - accuracy: 0.7710 - loss: 0.6115 - val_accuracy: 0.6291 - val_loss: 1.2083\n",
      "Epoch 18/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 71ms/step - accuracy: 0.7643 - loss: 0.6375 - val_accuracy: 0.6266 - val_loss: 1.1723\n",
      "Epoch 19/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 70ms/step - accuracy: 0.7701 - loss: 0.6186 - val_accuracy: 0.6261 - val_loss: 1.1532\n",
      "Epoch 20/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 72ms/step - accuracy: 0.7660 - loss: 0.6212 - val_accuracy: 0.6284 - val_loss: 1.1665\n",
      "Epoch 21/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 71ms/step - accuracy: 0.7742 - loss: 0.6147 - val_accuracy: 0.6300 - val_loss: 1.1704\n",
      "Epoch 22/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 71ms/step - accuracy: 0.7716 - loss: 0.6061 - val_accuracy: 0.6336 - val_loss: 1.1664\n",
      "Epoch 23/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 71ms/step - accuracy: 0.7744 - loss: 0.6157 - val_accuracy: 0.6312 - val_loss: 1.1721\n",
      "Epoch 24/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 72ms/step - accuracy: 0.7702 - loss: 0.6285 - val_accuracy: 0.6169 - val_loss: 1.1661\n",
      "Epoch 25/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 71ms/step - accuracy: 0.7754 - loss: 0.6047 - val_accuracy: 0.6156 - val_loss: 1.1420\n",
      "Epoch 26/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 72ms/step - accuracy: 0.7683 - loss: 0.6205 - val_accuracy: 0.6300 - val_loss: 1.1660\n",
      "Epoch 27/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 73ms/step - accuracy: 0.7735 - loss: 0.6156 - val_accuracy: 0.6247 - val_loss: 1.1746\n",
      "Epoch 28/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 73ms/step - accuracy: 0.7778 - loss: 0.6003 - val_accuracy: 0.6290 - val_loss: 1.1532\n",
      "Epoch 29/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 72ms/step - accuracy: 0.7708 - loss: 0.6169 - val_accuracy: 0.6346 - val_loss: 1.1756\n",
      "Epoch 30/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 72ms/step - accuracy: 0.7764 - loss: 0.6083 - val_accuracy: 0.6119 - val_loss: 1.2002\n",
      "Epoch 31/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 72ms/step - accuracy: 0.7797 - loss: 0.6003 - val_accuracy: 0.6208 - val_loss: 1.2015\n",
      "Epoch 32/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 69ms/step - accuracy: 0.7748 - loss: 0.6155 - val_accuracy: 0.6241 - val_loss: 1.1418\n",
      "Epoch 33/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 72ms/step - accuracy: 0.7779 - loss: 0.6014 - val_accuracy: 0.6297 - val_loss: 1.1704\n",
      "Epoch 34/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 74ms/step - accuracy: 0.7730 - loss: 0.6083 - val_accuracy: 0.6314 - val_loss: 1.1339\n",
      "Epoch 35/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 70ms/step - accuracy: 0.7725 - loss: 0.6155 - val_accuracy: 0.6244 - val_loss: 1.1906\n",
      "Epoch 36/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 70ms/step - accuracy: 0.7770 - loss: 0.6075 - val_accuracy: 0.6206 - val_loss: 1.1412\n",
      "Epoch 37/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 70ms/step - accuracy: 0.7723 - loss: 0.6070 - val_accuracy: 0.6330 - val_loss: 1.1606\n",
      "Epoch 38/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 73ms/step - accuracy: 0.7723 - loss: 0.6042 - val_accuracy: 0.6296 - val_loss: 1.1617\n",
      "Epoch 39/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 72ms/step - accuracy: 0.7792 - loss: 0.6020 - val_accuracy: 0.6276 - val_loss: 1.2154\n",
      "Epoch 40/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 73ms/step - accuracy: 0.7728 - loss: 0.6132 - val_accuracy: 0.6258 - val_loss: 1.2011\n",
      "Epoch 41/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 73ms/step - accuracy: 0.7742 - loss: 0.6147 - val_accuracy: 0.6245 - val_loss: 1.1492\n",
      "Epoch 42/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 73ms/step - accuracy: 0.7757 - loss: 0.6032 - val_accuracy: 0.6340 - val_loss: 1.1550\n",
      "Epoch 43/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 72ms/step - accuracy: 0.7824 - loss: 0.5889 - val_accuracy: 0.6287 - val_loss: 1.1313\n",
      "Epoch 44/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 73ms/step - accuracy: 0.7697 - loss: 0.6140 - val_accuracy: 0.6393 - val_loss: 1.1413\n",
      "Epoch 45/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 74ms/step - accuracy: 0.7780 - loss: 0.5998 - val_accuracy: 0.6311 - val_loss: 1.2095\n",
      "Epoch 46/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 72ms/step - accuracy: 0.7801 - loss: 0.5925 - val_accuracy: 0.6276 - val_loss: 1.1553\n",
      "Epoch 47/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 73ms/step - accuracy: 0.7791 - loss: 0.5911 - val_accuracy: 0.6257 - val_loss: 1.1616\n",
      "Epoch 48/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 73ms/step - accuracy: 0.7743 - loss: 0.6032 - val_accuracy: 0.6388 - val_loss: 1.1790\n",
      "Epoch 49/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 74ms/step - accuracy: 0.7805 - loss: 0.5985 - val_accuracy: 0.6335 - val_loss: 1.1743\n",
      "Epoch 50/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 73ms/step - accuracy: 0.7836 - loss: 0.5882 - val_accuracy: 0.6354 - val_loss: 1.1546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22d9ea7e5a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, validation_data=val_generator, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "839695c4-2491-4fb5-8f29-2af6efd00f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 71ms/step - accuracy: 0.7830 - loss: 0.5879 - val_accuracy: 0.6297 - val_loss: 1.1505\n",
      "Epoch 2/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 69ms/step - accuracy: 0.7805 - loss: 0.5881 - val_accuracy: 0.6321 - val_loss: 1.1576\n",
      "Epoch 3/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 69ms/step - accuracy: 0.7781 - loss: 0.5967 - val_accuracy: 0.6276 - val_loss: 1.1695\n",
      "Epoch 4/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 69ms/step - accuracy: 0.7842 - loss: 0.5867 - val_accuracy: 0.6342 - val_loss: 1.1732\n",
      "Epoch 5/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 69ms/step - accuracy: 0.7766 - loss: 0.6083 - val_accuracy: 0.6351 - val_loss: 1.1775\n",
      "Epoch 6/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 69ms/step - accuracy: 0.7809 - loss: 0.5930 - val_accuracy: 0.6208 - val_loss: 1.2052\n",
      "Epoch 7/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 70ms/step - accuracy: 0.7790 - loss: 0.6022 - val_accuracy: 0.6388 - val_loss: 1.1674\n",
      "Epoch 8/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 72ms/step - accuracy: 0.7813 - loss: 0.5933 - val_accuracy: 0.6325 - val_loss: 1.1393\n",
      "Epoch 9/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 72ms/step - accuracy: 0.7869 - loss: 0.5837 - val_accuracy: 0.6250 - val_loss: 1.1658\n",
      "Epoch 10/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 72ms/step - accuracy: 0.7818 - loss: 0.5809 - val_accuracy: 0.6337 - val_loss: 1.1496\n",
      "Epoch 11/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 70ms/step - accuracy: 0.7867 - loss: 0.5863 - val_accuracy: 0.6262 - val_loss: 1.1542\n",
      "Epoch 12/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 69ms/step - accuracy: 0.7791 - loss: 0.5973 - val_accuracy: 0.6268 - val_loss: 1.1526\n",
      "Epoch 13/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 69ms/step - accuracy: 0.7833 - loss: 0.5878 - val_accuracy: 0.6283 - val_loss: 1.1535\n",
      "Epoch 14/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 69ms/step - accuracy: 0.7895 - loss: 0.5722 - val_accuracy: 0.6326 - val_loss: 1.1493\n",
      "Epoch 15/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 69ms/step - accuracy: 0.7829 - loss: 0.5941 - val_accuracy: 0.6237 - val_loss: 1.1549\n",
      "Epoch 16/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 71ms/step - accuracy: 0.7834 - loss: 0.5804 - val_accuracy: 0.6315 - val_loss: 1.1800\n",
      "Epoch 17/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 72ms/step - accuracy: 0.7845 - loss: 0.5785 - val_accuracy: 0.6237 - val_loss: 1.1722\n",
      "Epoch 18/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 71ms/step - accuracy: 0.7799 - loss: 0.5875 - val_accuracy: 0.6148 - val_loss: 1.2243\n",
      "Epoch 19/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 72ms/step - accuracy: 0.7830 - loss: 0.5940 - val_accuracy: 0.6213 - val_loss: 1.1800\n",
      "Epoch 20/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 72ms/step - accuracy: 0.7850 - loss: 0.5746 - val_accuracy: 0.6310 - val_loss: 1.1896\n",
      "Epoch 21/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 73ms/step - accuracy: 0.7877 - loss: 0.5740 - val_accuracy: 0.6162 - val_loss: 1.2301\n",
      "Epoch 22/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 73ms/step - accuracy: 0.7841 - loss: 0.5897 - val_accuracy: 0.6213 - val_loss: 1.1464\n",
      "Epoch 23/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 73ms/step - accuracy: 0.7843 - loss: 0.5849 - val_accuracy: 0.6310 - val_loss: 1.1676\n",
      "Epoch 24/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 75ms/step - accuracy: 0.7817 - loss: 0.5834 - val_accuracy: 0.6272 - val_loss: 1.1908\n",
      "Epoch 25/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 73ms/step - accuracy: 0.7875 - loss: 0.5757 - val_accuracy: 0.6275 - val_loss: 1.1589\n",
      "Epoch 26/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1470s\u001b[0m 3s/step - accuracy: 0.7825 - loss: 0.5880 - val_accuracy: 0.6386 - val_loss: 1.1732\n",
      "Epoch 27/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 75ms/step - accuracy: 0.7807 - loss: 0.5931 - val_accuracy: 0.6181 - val_loss: 1.2582\n",
      "Epoch 28/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 75ms/step - accuracy: 0.7837 - loss: 0.5774 - val_accuracy: 0.6268 - val_loss: 1.1484\n",
      "Epoch 29/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 76ms/step - accuracy: 0.7868 - loss: 0.5810 - val_accuracy: 0.6211 - val_loss: 1.1788\n",
      "Epoch 30/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 77ms/step - accuracy: 0.7879 - loss: 0.5768 - val_accuracy: 0.6297 - val_loss: 1.1846\n",
      "Epoch 31/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 76ms/step - accuracy: 0.7883 - loss: 0.5754 - val_accuracy: 0.6287 - val_loss: 1.1553\n",
      "Epoch 32/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 77ms/step - accuracy: 0.7870 - loss: 0.5743 - val_accuracy: 0.6325 - val_loss: 1.1647\n",
      "Epoch 33/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 70ms/step - accuracy: 0.7867 - loss: 0.5748 - val_accuracy: 0.6304 - val_loss: 1.1866\n",
      "Epoch 34/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 62ms/step - accuracy: 0.7885 - loss: 0.5677 - val_accuracy: 0.6304 - val_loss: 1.2276\n",
      "Epoch 35/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 62ms/step - accuracy: 0.7868 - loss: 0.5730 - val_accuracy: 0.6291 - val_loss: 1.1850\n",
      "Epoch 36/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 60ms/step - accuracy: 0.7846 - loss: 0.5790 - val_accuracy: 0.6351 - val_loss: 1.1172\n",
      "Epoch 37/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 60ms/step - accuracy: 0.7933 - loss: 0.5676 - val_accuracy: 0.6300 - val_loss: 1.1755\n",
      "Epoch 38/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 60ms/step - accuracy: 0.7925 - loss: 0.5662 - val_accuracy: 0.6326 - val_loss: 1.1792\n",
      "Epoch 39/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 60ms/step - accuracy: 0.7844 - loss: 0.5766 - val_accuracy: 0.6294 - val_loss: 1.2365\n",
      "Epoch 40/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 60ms/step - accuracy: 0.7867 - loss: 0.5770 - val_accuracy: 0.6340 - val_loss: 1.1708\n",
      "Epoch 41/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 60ms/step - accuracy: 0.7876 - loss: 0.5747 - val_accuracy: 0.6361 - val_loss: 1.1586\n",
      "Epoch 42/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 60ms/step - accuracy: 0.7858 - loss: 0.5754 - val_accuracy: 0.6278 - val_loss: 1.1934\n",
      "Epoch 43/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 60ms/step - accuracy: 0.7874 - loss: 0.5698 - val_accuracy: 0.6060 - val_loss: 1.2248\n",
      "Epoch 44/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 60ms/step - accuracy: 0.7872 - loss: 0.5706 - val_accuracy: 0.6252 - val_loss: 1.1877\n",
      "Epoch 45/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 60ms/step - accuracy: 0.7901 - loss: 0.5730 - val_accuracy: 0.6361 - val_loss: 1.1622\n",
      "Epoch 46/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 60ms/step - accuracy: 0.7906 - loss: 0.5613 - val_accuracy: 0.6343 - val_loss: 1.1611\n",
      "Epoch 47/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 60ms/step - accuracy: 0.7881 - loss: 0.5678 - val_accuracy: 0.6372 - val_loss: 1.2028\n",
      "Epoch 48/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 60ms/step - accuracy: 0.7889 - loss: 0.5704 - val_accuracy: 0.6218 - val_loss: 1.2096\n",
      "Epoch 49/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 60ms/step - accuracy: 0.7938 - loss: 0.5697 - val_accuracy: 0.6329 - val_loss: 1.1319\n",
      "Epoch 50/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 61ms/step - accuracy: 0.7938 - loss: 0.5673 - val_accuracy: 0.6296 - val_loss: 1.1807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22d8a203800>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, validation_data=val_generator, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04a094cc-4245-41cf-b106-acd5fe739f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model4.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d135f45-9970-481a-9cdd-fd4fe3436560",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"my_model5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ead22a2a-8f84-423f-9975-927f7eed7ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 83ms/step - accuracy: 0.7924 - loss: 0.5638 - val_accuracy: 0.6339 - val_loss: 1.1469\n",
      "Epoch 2/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 74ms/step - accuracy: 0.7918 - loss: 0.5612 - val_accuracy: 0.6371 - val_loss: 1.1576\n",
      "Epoch 3/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 72ms/step - accuracy: 0.7963 - loss: 0.5579 - val_accuracy: 0.6225 - val_loss: 1.1924\n",
      "Epoch 4/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 72ms/step - accuracy: 0.7912 - loss: 0.5698 - val_accuracy: 0.6322 - val_loss: 1.1830\n",
      "Epoch 5/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 72ms/step - accuracy: 0.7883 - loss: 0.5713 - val_accuracy: 0.6218 - val_loss: 1.1182\n",
      "Epoch 6/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 72ms/step - accuracy: 0.7884 - loss: 0.5634 - val_accuracy: 0.6308 - val_loss: 1.2058\n",
      "Epoch 7/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 72ms/step - accuracy: 0.7920 - loss: 0.5624 - val_accuracy: 0.6372 - val_loss: 1.2238\n",
      "Epoch 8/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 72ms/step - accuracy: 0.7996 - loss: 0.5586 - val_accuracy: 0.6321 - val_loss: 1.2265\n",
      "Epoch 9/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 73ms/step - accuracy: 0.7901 - loss: 0.5723 - val_accuracy: 0.6344 - val_loss: 1.2149\n",
      "Epoch 10/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 73ms/step - accuracy: 0.7966 - loss: 0.5565 - val_accuracy: 0.6284 - val_loss: 1.2210\n",
      "Epoch 11/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 73ms/step - accuracy: 0.7950 - loss: 0.5641 - val_accuracy: 0.6368 - val_loss: 1.1838\n",
      "Epoch 12/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 73ms/step - accuracy: 0.7910 - loss: 0.5668 - val_accuracy: 0.6300 - val_loss: 1.1809\n",
      "Epoch 13/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 72ms/step - accuracy: 0.7928 - loss: 0.5659 - val_accuracy: 0.6374 - val_loss: 1.1820\n",
      "Epoch 14/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 73ms/step - accuracy: 0.7983 - loss: 0.5481 - val_accuracy: 0.6332 - val_loss: 1.1801\n",
      "Epoch 15/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 73ms/step - accuracy: 0.7933 - loss: 0.5592 - val_accuracy: 0.6248 - val_loss: 1.1803\n",
      "Epoch 16/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 73ms/step - accuracy: 0.7918 - loss: 0.5628 - val_accuracy: 0.6333 - val_loss: 1.2066\n",
      "Epoch 17/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 73ms/step - accuracy: 0.7963 - loss: 0.5648 - val_accuracy: 0.6400 - val_loss: 1.1676\n",
      "Epoch 18/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 73ms/step - accuracy: 0.7907 - loss: 0.5689 - val_accuracy: 0.6347 - val_loss: 1.1955\n",
      "Epoch 19/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 73ms/step - accuracy: 0.7938 - loss: 0.5610 - val_accuracy: 0.6195 - val_loss: 1.2098\n",
      "Epoch 20/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1555s\u001b[0m 3s/step - accuracy: 0.7918 - loss: 0.5649 - val_accuracy: 0.6336 - val_loss: 1.1913\n",
      "Epoch 21/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 74ms/step - accuracy: 0.7944 - loss: 0.5555 - val_accuracy: 0.6346 - val_loss: 1.1662\n",
      "Epoch 22/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 74ms/step - accuracy: 0.7974 - loss: 0.5600 - val_accuracy: 0.6239 - val_loss: 1.2026\n",
      "Epoch 23/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 74ms/step - accuracy: 0.7952 - loss: 0.5589 - val_accuracy: 0.6402 - val_loss: 1.1850\n",
      "Epoch 24/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 77ms/step - accuracy: 0.7928 - loss: 0.5551 - val_accuracy: 0.6215 - val_loss: 1.1855\n",
      "Epoch 25/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 74ms/step - accuracy: 0.7933 - loss: 0.5652 - val_accuracy: 0.6425 - val_loss: 1.2350\n",
      "Epoch 26/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 74ms/step - accuracy: 0.7980 - loss: 0.5531 - val_accuracy: 0.6318 - val_loss: 1.1339\n",
      "Epoch 27/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 74ms/step - accuracy: 0.7988 - loss: 0.5461 - val_accuracy: 0.6329 - val_loss: 1.1761\n",
      "Epoch 28/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 75ms/step - accuracy: 0.7928 - loss: 0.5608 - val_accuracy: 0.6219 - val_loss: 1.1911\n",
      "Epoch 29/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 74ms/step - accuracy: 0.7970 - loss: 0.5539 - val_accuracy: 0.6361 - val_loss: 1.1538\n",
      "Epoch 30/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 116ms/step - accuracy: 0.7987 - loss: 0.5505 - val_accuracy: 0.6340 - val_loss: 1.1671\n",
      "Epoch 31/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 74ms/step - accuracy: 0.8008 - loss: 0.5427 - val_accuracy: 0.6393 - val_loss: 1.1657\n",
      "Epoch 32/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 74ms/step - accuracy: 0.7941 - loss: 0.5528 - val_accuracy: 0.6308 - val_loss: 1.1495\n",
      "Epoch 33/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 74ms/step - accuracy: 0.7936 - loss: 0.5559 - val_accuracy: 0.6300 - val_loss: 1.1805\n",
      "Epoch 34/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 64ms/step - accuracy: 0.7967 - loss: 0.5630 - val_accuracy: 0.6340 - val_loss: 1.1907\n",
      "Epoch 35/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 62ms/step - accuracy: 0.7972 - loss: 0.5472 - val_accuracy: 0.6318 - val_loss: 1.1447\n",
      "Epoch 36/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 62ms/step - accuracy: 0.7993 - loss: 0.5490 - val_accuracy: 0.6294 - val_loss: 1.1997\n",
      "Epoch 37/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 62ms/step - accuracy: 0.8009 - loss: 0.5433 - val_accuracy: 0.6427 - val_loss: 1.1960\n",
      "Epoch 38/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 62ms/step - accuracy: 0.7987 - loss: 0.5462 - val_accuracy: 0.6379 - val_loss: 1.1909\n",
      "Epoch 39/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 62ms/step - accuracy: 0.7956 - loss: 0.5636 - val_accuracy: 0.6407 - val_loss: 1.2054\n",
      "Epoch 40/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 67ms/step - accuracy: 0.8006 - loss: 0.5421 - val_accuracy: 0.6321 - val_loss: 1.1836\n",
      "Epoch 41/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 424ms/step - accuracy: 0.8003 - loss: 0.5412 - val_accuracy: 0.6335 - val_loss: 1.1937\n",
      "Epoch 42/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 266ms/step - accuracy: 0.7989 - loss: 0.5541 - val_accuracy: 0.6307 - val_loss: 1.1990\n",
      "Epoch 43/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 67ms/step - accuracy: 0.7992 - loss: 0.5542 - val_accuracy: 0.6329 - val_loss: 1.1798\n",
      "Epoch 44/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 64ms/step - accuracy: 0.8054 - loss: 0.5333 - val_accuracy: 0.6282 - val_loss: 1.1589\n",
      "Epoch 45/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 64ms/step - accuracy: 0.7899 - loss: 0.5620 - val_accuracy: 0.6375 - val_loss: 1.1826\n",
      "Epoch 46/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 63ms/step - accuracy: 0.7989 - loss: 0.5539 - val_accuracy: 0.6330 - val_loss: 1.1928\n",
      "Epoch 47/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 63ms/step - accuracy: 0.8008 - loss: 0.5414 - val_accuracy: 0.6436 - val_loss: 1.2131\n",
      "Epoch 48/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 63ms/step - accuracy: 0.7935 - loss: 0.5495 - val_accuracy: 0.6296 - val_loss: 1.2130\n",
      "Epoch 49/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 63ms/step - accuracy: 0.8018 - loss: 0.5421 - val_accuracy: 0.6333 - val_loss: 1.2223\n",
      "Epoch 50/50\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 63ms/step - accuracy: 0.7977 - loss: 0.5487 - val_accuracy: 0.6364 - val_loss: 1.1609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22d89025880>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, validation_data=val_generator, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e9a266-81e4-4687-8f30-5c489620a88d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
